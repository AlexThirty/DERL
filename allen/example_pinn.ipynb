{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "seed = 30\n",
    "import random\n",
    "font = {'size'   : 16}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)\n",
    "lam = 0.01\n",
    "\n",
    "import os\n",
    "if not os.path.exists('example'):\n",
    "    os.makedirs('example')\n",
    "\n",
    "\n",
    "# Functions for the true solution\n",
    "\n",
    "def allen_cahn_true(x: np.array):\n",
    "    return np.sin(np.pi*x[:,0])*np.sin(np.pi*x[:,1])\n",
    "\n",
    "def allen_cahn_forcing(x: np.array):\n",
    "    return -2*lam*np.pi**2*allen_cahn_true(x) + allen_cahn_true(x)**3 - allen_cahn_true(x)\n",
    "\n",
    "def allen_cahn_pdv(x: np.array):\n",
    "    ux = np.pi*np.cos(np.pi*x[:,0])*np.sin(np.pi*x[:,1])\n",
    "    uy = np.pi*np.sin(np.pi*x[:,0])*np.cos(np.pi*x[:,1])\n",
    "    return np.column_stack((ux, uy))\n",
    "\n",
    "def allen_cahn_hes(x: np.array):\n",
    "    uxx = -np.pi**2*np.sin(np.pi*x[:,0])*np.sin(np.pi*x[:,1])\n",
    "    uxy = np.pi**2*np.cos(np.pi*x[:,0])*np.cos(np.pi*x[:,1])\n",
    "    uyy = -np.pi**2*np.sin(np.pi*x[:,0])*np.sin(np.pi*x[:,1])\n",
    "    return np.column_stack((uxx, uxy, uxy, uyy)).reshape((-1,2,2))\n",
    "\n",
    "xmin = -1.\n",
    "xmax = 1.\n",
    "dx = 0.02\n",
    "\n",
    "n_rand = 1000\n",
    "\n",
    "\n",
    "# Grid of points in the domain\n",
    "x = np.arange(xmin+dx, xmax, dx)\n",
    "y = np.arange(xmin+dx, xmax, dx)\n",
    "x_pts, y_pts = np.meshgrid(x, y)\n",
    "x_pts = x_pts.reshape((-1,1))\n",
    "y_pts = y_pts.reshape((-1,1))\n",
    "pts = np.column_stack((x_pts, y_pts))\n",
    "u_grid = allen_cahn_true(pts).reshape((-1,1))\n",
    "pdv_grid = allen_cahn_pdv(pts)\n",
    "hes_grid = allen_cahn_hes(pts)\n",
    "\n",
    "print(f'u_grid.shape: {u_grid.shape}')\n",
    "print(f'pts.shape: {pts.shape}')\n",
    "print(f'pdv_grid.shape: {pdv_grid.shape}')\n",
    "print(f'hes_grid.shape: {hes_grid.shape}')\n",
    "\n",
    "grid_exampleset = TensorDataset(torch.tensor(pts, dtype=torch.float32), torch.tensor(u_grid, dtype=torch.float32), torch.tensor(pdv_grid, dtype=torch.float32), torch.tensor(hes_grid, dtype=torch.float32))\n",
    "\n",
    "\n",
    "# Boundary conditions\n",
    "x = np.arange(xmin, xmax+dx, dx)\n",
    "y = np.array([xmin]*len(x))\n",
    "x_pts = x.reshape((-1,1))\n",
    "y_pts = y.reshape((-1,1))\n",
    "pts = np.column_stack((x_pts, y_pts))\n",
    "# Get first boudary condition\n",
    "u_bc = allen_cahn_true(pts).reshape((-1,1))\n",
    "pts_bc = pts\n",
    "\n",
    "x = np.arange(xmin, xmax+dx, dx)\n",
    "y = np.array([xmax]*len(x))\n",
    "x_pts = x.reshape((-1,1))\n",
    "y_pts = y.reshape((-1,1))\n",
    "# Append second boundary condition\n",
    "pts = np.column_stack((x_pts, y_pts))\n",
    "u_bc = np.row_stack((u_bc, allen_cahn_true(pts).reshape((-1,1))))\n",
    "pts_bc = np.row_stack((pts_bc, pts))\n",
    "\n",
    "\n",
    "x = np.array([xmin]*len(y))\n",
    "y = np.arange(xmin, xmax+dx, dx)\n",
    "x_pts = x.reshape((-1,1))\n",
    "y_pts = y.reshape((-1,1))\n",
    "# Append third boundary condition\n",
    "pts = np.column_stack((x_pts, y_pts))\n",
    "u_bc = np.row_stack((u_bc, allen_cahn_true(pts).reshape((-1,1))))\n",
    "pts_bc = np.row_stack((pts_bc, pts))\n",
    "\n",
    "x = np.array([xmax]*len(y))\n",
    "y = np.arange(xmin, xmax+dx, dx)\n",
    "x_pts = x.reshape((-1,1))\n",
    "y_pts = y.reshape((-1,1))\n",
    "# Append fourth boundary condition\n",
    "pts = np.column_stack((x_pts, y_pts))\n",
    "u_bc = np.row_stack((u_bc, allen_cahn_true(pts).reshape((-1,1))))\n",
    "pts_bc = np.row_stack((pts_bc, pts))\n",
    "\n",
    "print(f'u_bc.shape: {u_bc.shape}')\n",
    "print(f'pts_bc.shape: {pts_bc.shape}')\n",
    "\n",
    "bc_exampleset = TensorDataset(torch.tensor(pts_bc, dtype=torch.float32), torch.tensor(u_bc, dtype=torch.float32))\n",
    "\n",
    "\n",
    "# Plot the solution\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Plot the solution on a grid of points\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x = np.arange(xmin, xmax+dx, dx)\n",
    "y = np.arange(xmin, xmax+dx, dx)\n",
    "x_pts, y_pts = np.meshgrid(x, y)\n",
    "z = allen_cahn_true(np.column_stack((x_pts.reshape((-1,1)), y_pts.reshape((-1,1))))).reshape(x_pts.shape)\n",
    "ax.plot_surface(x_pts, y_pts, z, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('u')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Now plot with a heatmap\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(z, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot the forcing on a grid of points\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x = np.arange(xmin, xmax+dx, dx)\n",
    "y = np.arange(xmin, xmax+dx, dx)\n",
    "x_pts, y_pts = np.meshgrid(x, y)\n",
    "z = allen_cahn_forcing(np.column_stack((x_pts.reshape((-1,1)), y_pts.reshape((-1,1))))).reshape((x_pts.shape))\n",
    "ax.plot_surface(x_pts, y_pts, z, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Not plot with a heatmap\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(z, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.func import vmap, jacrev, hessian\n",
    "\n",
    "lam = 0.01\n",
    "\n",
    "def allen_cahn_true(x: torch.Tensor):\n",
    "    return torch.sin(torch.pi*x[:,0])*torch.sin(torch.pi*x[:,1])\n",
    "\n",
    "def allen_cahn_forcing(x: torch.Tensor):\n",
    "    return -2*lam*torch.pi**2*allen_cahn_true(x) + allen_cahn_true(x)**3 - allen_cahn_true(x)\n",
    "\n",
    "def allen_cahn_pdv(x: torch.Tensor):\n",
    "    ux = torch.pi*torch.cos(torch.pi*x[:,0])*torch.sin(torch.pi*x[:,1])\n",
    "    uy = torch.pi*torch.sin(torch.pi*x[:,0])*torch.cos(torch.pi*x[:,1])\n",
    "    return torch.column_stack((ux, uy))\n",
    "\n",
    "# Density network\n",
    "class AllenNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 bc_weight: float,\n",
    "                 sys_weight: float,\n",
    "                 pde_weight: float,\n",
    "                 hidden_units: list,\n",
    "                 device: str,\n",
    "                 *args,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Save the parameters\n",
    "        self.bc_weight = bc_weight\n",
    "        self.pde_weight = pde_weight\n",
    "        self.sys_weight = sys_weight\n",
    "        self.hidden_units = hidden_units\n",
    "        self.device = device\n",
    "\n",
    "        self.in_dim = 2\n",
    "        self.out_dim = 1\n",
    "        # Add the first in_dimension\n",
    "        hidden_units = [self.in_dim] + hidden_units\n",
    "        # Define the net\n",
    "        net = nn.Sequential()\n",
    "        for i in range(len(hidden_units)-1):\n",
    "            net.add_module(f'layer_{i}', nn.Linear(hidden_units[i], hidden_units[i+1]))\n",
    "            net.add_module(f'activation_{i}', nn.Tanh())\n",
    "        net.add_module(f'layer_{len(hidden_units)-1}', nn.Linear(hidden_units[-1], self.out_dim))\n",
    "        # Save the network\n",
    "        self.net = net.to(self.device)\n",
    "        # Define the optimizer\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # Forward function\n",
    "        return self.net(x)\n",
    "    \n",
    "    def forward_single(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # Forward function for individual samples\n",
    "        return self.net(x.reshape((1,-1))).reshape((-1))\n",
    "    \n",
    "    def loss_fn(self,\n",
    "        x:torch.Tensor,\n",
    "        x_bc:torch.Tensor=None,\n",
    "        y_bc:torch.Tensor=None,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # Get the prediction\n",
    "        y_pred = self.forward(x)\n",
    "        # Get the partial derivatives from the network\n",
    "        Dy_pred = vmap(jacrev(self.forward_single))(x)[:,0,:]\n",
    "        Hy_pred = vmap(hessian(self.forward_single))(x)[:,0,:,:]\n",
    "        \n",
    "        # lambda*(uxx + uyy) - u + u^3 = 0\n",
    "        # Calculate the pde_residual\n",
    "        pde_pred = lam*(Hy_pred[:,0,0] + Hy_pred[:,1,1]) - y_pred.reshape((-1)) + y_pred.reshape((-1))**3\n",
    "        # Calculate the loss\n",
    "        pde_loss = nn.MSELoss()(pde_pred, allen_cahn_forcing(x))\n",
    "    \n",
    "        \n",
    "        y_bc_pred = self.forward(x_bc)\n",
    "        bc_loss = nn.MSELoss()(y_bc_pred.reshape((-1)), y_bc.reshape((-1)))\n",
    "\n",
    "    \n",
    "        # Total loss\n",
    "        tot_loss = self.pde_weight*pde_loss + self.bc_weight*bc_loss\n",
    "        return tot_loss\n",
    "    \n",
    "    def eval_losses(self, step:int,\n",
    "        x:torch.Tensor,\n",
    "        y:torch.Tensor,\n",
    "        x_bc:torch.Tensor=None,\n",
    "        y_bc:torch.Tensor=None,\n",
    "        print_to_screen:bool=False,    \n",
    "    ):\n",
    "        # Check that the mode parameter is correct\n",
    "        # Get the prediction\n",
    "        y_pred = self.forward(x)\n",
    "        # Get the partial derivatives from the network\n",
    "        Dy_pred = vmap(jacrev(self.forward_single))(x)[:,0,:]\n",
    "        Hy_pred = vmap(hessian(self.forward_single))(x)[:,0,:,:]\n",
    "            \n",
    "        # lambda*(uxx + uyy) - u + u^3 = f\n",
    "        # Calculate the pde_residual\n",
    "        pde_pred = lam*(Hy_pred[:,0,0] + Hy_pred[:,1,1]) - y_pred.reshape((-1)) + y_pred.reshape((-1))**3\n",
    "        # Calculate the loss\n",
    "        pde_loss = nn.MSELoss()(pde_pred, allen_cahn_forcing(x))\n",
    "        \n",
    "        # Loss wrt the true output\n",
    "        out_loss = nn.MSELoss()(y_pred, y)        \n",
    "        # Boundary condition\n",
    "        y_bc_pred = self.forward(x_bc)\n",
    "        bc_loss = nn.MSELoss()(y_bc_pred.reshape((-1)), y_bc.reshape((-1)))\n",
    "        \n",
    "        # Total loss\n",
    "        tot_loss = pde_loss + self.bc_weight*bc_loss\n",
    "        \n",
    "        \n",
    "        if print_to_screen:\n",
    "            print(f'Step: {step}, total loss: {tot_loss}')\n",
    "            print(f'pde loss: {pde_loss}, out loss {out_loss}, bc loss: {bc_loss}')\n",
    "        \n",
    "        \n",
    "        return step, out_loss, pde_loss, bc_loss, tot_loss\n",
    "    \n",
    "    def evaluate_forcing(self, x):\n",
    "        # Get the prediction\n",
    "        y_pred = self.forward(x)\n",
    "        # Get the partial derivatives from the network\n",
    "        Dy_pred = vmap(jacrev(self.forward_single))(x)[:,0,:]\n",
    "        Hy_pred = vmap(hessian(self.forward_single))(x)[:,0,:,:]\n",
    "            \n",
    "        # lambda*(uxx + uyy) - u + u^3 = 0\n",
    "        # Calculate the pde_residual\n",
    "        pde_pred = lam*(Hy_pred[:,0,0] + Hy_pred[:,1,1]) - y_pred.reshape((-1)) + y_pred.reshape((-1))**3\n",
    "                \n",
    "        return pde_pred\n",
    "    \n",
    "    def evaluate_consistency(self, x):\n",
    "        # Get the prediction\n",
    "        y_pred = self.forward(x)\n",
    "        # Get the partial derivatives from the network\n",
    "        Dy_pred = vmap(jacrev(self.forward_single))(x)[:,0,:]\n",
    "        Hy_pred = vmap(hessian(self.forward_single))(x)[:,0,:,:]\n",
    "            \n",
    "        # lambda*(uxx + uyy) - u + u^3 = 0\n",
    "        # Calculate the pde_residual\n",
    "        pde_pred = lam*(Hy_pred[:,0,0] + Hy_pred[:,1,1]) - y_pred.reshape((-1)) + y_pred.reshape((-1))**3\n",
    "                \n",
    "        return torch.abs(pde_pred - allen_cahn_forcing(x))\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "seed = 30\n",
    "from itertools import cycle\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')   \n",
    "\n",
    "\n",
    "train_dataset = test_dataset = grid_exampleset\n",
    "bc_dataset = bc_exampleset\n",
    "#else:\n",
    "#    bc_dataset = None\n",
    "# Generate the dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, 10000, shuffle=True)\n",
    "bc_dataloader = DataLoader(bc_dataset, batch_size, shuffle=True)\n",
    "\n",
    "print('Data loaded!')\n",
    "\n",
    "print(train_dataset[:][0].shape)\n",
    "\n",
    "activation = torch.nn.Tanh()\n",
    "\n",
    "model = AllenNet(\n",
    "    bc_weight=1.,\n",
    "    pde_weight=1.,\n",
    "    sys_weight=1.,\n",
    "    hidden_units=[50 for _ in range(4)],\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "step_list= []\n",
    "out_losses_train = []\n",
    "pde_losses_train = []\n",
    "tot_losses_train = []\n",
    "bc_losses_train = []\n",
    "\n",
    "step_list_test = []\n",
    "out_losses_test = []\n",
    "pde_losses_test = []\n",
    "tot_losses_test = []\n",
    "bc_losses_test = []\n",
    "times_test = []\n",
    "\n",
    "from torch.optim import LBFGS, Adam\n",
    "\n",
    "\n",
    "opt = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "import time\n",
    "def train_loop(epochs:int,\n",
    "        train_dataloader:DataLoader,\n",
    "        test_dataloader:DataLoader,\n",
    "        bc_dataloader:DataLoader,\n",
    "        print_every:int=100):\n",
    "    \n",
    "    # Training mode for the network\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        step_prefix = epoch*len(train_dataloader)\n",
    "        start_time = time.time()\n",
    "        print(f'Epoch: {epoch}, step_prefix: {step_prefix}')\n",
    "        for step, (train_data, bc_data) in enumerate(zip(train_dataloader, cycle(bc_dataloader))):\n",
    "            \n",
    "            # Load batches from dataloaders\n",
    "            x_train = train_data[0].to(device).float().requires_grad_(True)\n",
    "            \n",
    "            y_train = train_data[1].to(device).float()\n",
    "            \n",
    "            x_bc = bc_data[0].to(device).float()\n",
    "            y_bc = bc_data[1].to(device).float()\n",
    "            \n",
    "            #if name == 'grid':\n",
    "            # Call zero grad on optimizer\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            loss = model.loss_fn(\n",
    "                x=x_train, x_bc=x_bc, y_bc=y_bc\n",
    "            )\n",
    "            # Backward the loss, calculate gradients\n",
    "            loss.backward()\n",
    "            # Optimizer step\n",
    "            opt.step()\n",
    "            # Update the learning rate schedulings\n",
    "            \n",
    "            # Printing\n",
    "            if (step_prefix+step) % print_every == 0:\n",
    "                #print('Train losses')\n",
    "                with torch.no_grad():\n",
    "                    step_val, out_loss_train, pde_loss_train, bc_loss_train, tot_loss_train = model.eval_losses(\n",
    "                        step = step_prefix+step,\n",
    "                        x=x_train, y=y_train, x_bc=x_bc, y_bc=y_bc, print_to_screen=True,\n",
    "                    )\n",
    "                    step_list.append(step_val)\n",
    "                    tot_losses_train.append(tot_loss_train)\n",
    "                    out_losses_train.append(out_loss_train)\n",
    "                    pde_losses_train.append(pde_loss_train)\n",
    "                    bc_losses_train.append(bc_loss_train)\n",
    "        \n",
    "        # Calculate and average the loss over the test dataloader\n",
    "        stop_time = time.time()\n",
    "        print(f'Epoch time: {stop_time-start_time}')\n",
    "        epoch_time = stop_time-start_time\n",
    "        times_test.append(epoch_time)\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        out_loss_test = 0.0\n",
    "        der_loss_test = 0.0\n",
    "        pde_loss_test = 0.0\n",
    "        tot_loss_test = 0.0\n",
    "        bc_loss_test = 0.0\n",
    "        hes_loss_test = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (test_data, bc_data) in zip(test_dataloader, cycle(bc_dataloader)):\n",
    "                x_test = test_data[0].to(device).float().requires_grad_(True)\n",
    "                y_test = test_data[1].to(device).float()\n",
    "\n",
    "                x_bc = bc_data[0].to(device).float()\n",
    "                y_bc = bc_data[1].to(device).float()\n",
    "                \n",
    "                step_test, out_loss, pde_loss, bc_loss, tot_loss = model.eval_losses(step=step_prefix+step,\n",
    "                                                                                        x=x_test, y=y_test, x_bc=x_bc, y_bc=y_bc)\n",
    "                \n",
    "                out_loss_test += out_loss.item()\n",
    "                pde_loss_test += pde_loss.item()\n",
    "                tot_loss_test += tot_loss.item()\n",
    "                bc_loss_test += bc_loss.item()\n",
    "                \n",
    "                test_loss += tot_loss.item()\n",
    "                \n",
    "            test_loss /= len(test_dataloader)\n",
    "            out_loss_test /= len(test_dataloader)\n",
    "            pde_loss_test /= len(test_dataloader)\n",
    "            tot_loss_test /= len(test_dataloader)\n",
    "            bc_loss_test /= len(test_dataloader)\n",
    "        \n",
    "        step_list_test.append(step_test)\n",
    "        out_losses_test.append(out_loss_test)\n",
    "        pde_losses_test.append(pde_loss_test)\n",
    "        tot_losses_test.append(tot_loss_test)\n",
    "        bc_losses_test.append(bc_loss_test)\n",
    "            \n",
    "        print(f\"Average test loss: {test_loss}\")\n",
    "        print(f\"Average output loss: {out_loss_test}\")\n",
    "        print(f\"Average PDE loss: {pde_loss_test}\")\n",
    "        print(f\"Average total loss: {tot_loss_test}\")\n",
    "        print(f\"Average bc loss: {bc_loss_test}\")\n",
    "\n",
    "\n",
    "train_loop(epochs=epochs, train_dataloader=train_dataloader, test_dataloader=test_dataloader, bc_dataloader=bc_dataloader, print_every=100)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from model import allen_cahn_true\n",
    "# Generate the grid for the true solution\n",
    "xmin = -1.\n",
    "xmax = 1.\n",
    "dx = 0.01\n",
    "x = np.arange(xmin, xmax+dx, dx)\n",
    "y = np.arange(xmin, xmax+dx, dx)\n",
    "x_pts, y_pts = np.meshgrid(x, y)\n",
    "pts = np.column_stack((x_pts.reshape((-1,1)), y_pts.reshape((-1,1))))\n",
    "u_grid = allen_cahn_true(torch.tensor(pts)).reshape((-1,1)).reshape(x_pts.shape)\n",
    "\n",
    "u_pred = model.forward(torch.tensor(pts).to(device).float()).detach().cpu().numpy().reshape(x_pts.shape)\n",
    "\n",
    "u_err = np.abs(u_grid - u_pred)\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "# Plot the predicted solution\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(u_pred, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "fig.suptitle('Predicted solution')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot the error wrt the true solution\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(u_err, cmap=cm.jet)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "fig.suptitle('Error of the predicted solution')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Convert the losses arrays\n",
    "epoch_list = torch.tensor(step_list).cpu().numpy()\n",
    "out_losses_train = torch.tensor(out_losses_train).cpu().numpy()\n",
    "pde_losses_train = torch.tensor(pde_losses_train).cpu().numpy()\n",
    "tot_losses_train = torch.tensor(tot_losses_train).cpu().numpy()\n",
    "bc_losses_train = torch.tensor(bc_losses_train).cpu().numpy()    \n",
    "\n",
    "\n",
    "N = 10\n",
    "l = len(np.convolve(out_losses_train, np.ones(N)/N, mode='valid'))\n",
    "plt.figure()\n",
    "plt.plot(epoch_list[:l], np.convolve(pde_losses_train, np.ones(N)/N, mode='valid'), label='pde_loss', color='red')\n",
    "plt.plot(epoch_list[:l], np.convolve(out_losses_train, np.ones(N)/N, mode='valid'), label='out_loss', color='green')\n",
    "plt.plot(epoch_list[:l], np.convolve(bc_losses_train, np.ones(N)/N, mode='valid'), label='bc_loss', color='purple')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.title('Losses of the student model')\n",
    "plt.xlabel('Training steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Convert the losses arrays\n",
    "epoch_list = torch.tensor(step_list_test).cpu().numpy()\n",
    "out_losses_test = torch.tensor(out_losses_test).cpu().numpy()\n",
    "pde_losses_test = torch.tensor(pde_losses_test).cpu().numpy()\n",
    "tot_losses_test = torch.tensor(tot_losses_test).cpu().numpy()\n",
    "bc_losses_test = torch.tensor(bc_losses_test).cpu().numpy()\n",
    "times_test = np.array(times_test)\n",
    "\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(epoch_list, pde_losses_test, label='pde_loss', color='red')\n",
    "plt.plot(epoch_list, out_losses_test, label='out_loss', color='green')\n",
    "plt.plot(epoch_list, bc_losses_test, label='bc_loss', color='purple')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.title('Losses of the student model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLgeneric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
